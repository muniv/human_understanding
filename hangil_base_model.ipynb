{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Other Libraries\n",
    "from sklearn.metrics import precision_score, recall_score, roc_curve, roc_auc_score, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_label = pd.read_csv(r'C:\\Users\\user\\Desktop\\work\\AI_study\\korea_univ_std\\ETRI_human\\test_code\\test_data\\train_label.csv')\n",
    "df_user_info = pd.read_csv(r'C:\\Users\\user\\Desktop\\work\\AI_study\\korea_univ_std\\ETRI_human\\test_code\\test_data\\user_info_2020.csv')\n",
    "df_user_sleep = pd.read_csv(r'C:\\Users\\user\\Desktop\\work\\AI_study\\korea_univ_std\\ETRI_human\\test_code\\test_data\\user_sleep_2020.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>date</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>user01</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>user01</td>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 subject_id        date  Q1  Q2  Q3  S1  S2  S3  S4\n",
       "0           0     user01  2020-08-30   1   0   0   1   1   0   0\n",
       "1           1     user01  2020-08-31   0   0   0   0   1   1   1\n",
       "2           2     user01  2020-09-01   0   0   0   0   1   1   1\n",
       "3           3     user01  2020-09-02   1   0   0   1   1   1   1\n",
       "4           4     user01  2020-09-03   1   0   0   0   1   1   1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. subject_id - 사용자 식별자\n",
    "\n",
    "2. age - 사용자 나이\n",
    "\n",
    "3. gender - 사용자 성별\n",
    "\n",
    "4. wakeupduration - 기상 시간\n",
    "\n",
    "5. lightsleepduration - 얕은 수면 시간\n",
    "\n",
    "6. deepsleepduration - 깊은 수면 시간\n",
    "\n",
    "7. remsleepduration - REM 수면 시간\n",
    "\n",
    "8. hr_average - 평균 심박수\n",
    "\n",
    "9. amCondition - 오전 컨디션\n",
    "\n",
    "10. pmStress - 오후 스트레스\n",
    "\n",
    "11. pmFatigue - 오후 피로\n",
    "\n",
    "12. date - 날짜\n",
    "'''\n",
    "\n",
    "col_list = ['subject_id','gender','wakeupduration','lightsleepduration','deepsleepduration','remsleepduration',\n",
    "            'hr_average','amCondition','pmStress','pmFatigue','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     userId    timezone        date     startDt       endDt  lastUpdate  \\\n",
      "351  user01  Asia/Seoul  2020-08-31  1598802240  1598830980  1598838373   \n",
      "352  user01  Asia/Seoul  2020-09-01  1598897280  1598922060  1598923633   \n",
      "353  user01  Asia/Seoul  2020-09-02  1598988060  1599012000  1599012074   \n",
      "354  user01  Asia/Seoul  2020-09-03  1599071220  1599098460  1599098830   \n",
      "355  user01  Asia/Seoul  2020-09-04  1599162960  1599185580  1599185829   \n",
      "..      ...         ...         ...         ...         ...         ...   \n",
      "507  user30  Asia/Seoul  2020-09-22  1600702320  1600728060  1600728134   \n",
      "508  user30  Asia/Seoul  2020-09-23  1600789560  1600814400  1600814550   \n",
      "509  user30  Asia/Seoul  2020-09-24  1600875720  1600896300  1600896726   \n",
      "510  user30  Asia/Seoul  2020-09-24  1600875720  1600900800  1600900872   \n",
      "511  user30  Asia/Seoul  2020-09-25  1600965120  1600987200  1600987323   \n",
      "\n",
      "     wakeupduration  lightsleepduration  deepsleepduration  wakeupcount  ...  \\\n",
      "351            3240               11700               6120            1  ...   \n",
      "352            1140                9660               6840            0  ...   \n",
      "353            2640                6360               7020            3  ...   \n",
      "354            1560                9360              10140            1  ...   \n",
      "355            1260                8580               8220            0  ...   \n",
      "..              ...                 ...                ...          ...  ...   \n",
      "507            3780               11340               4200            2  ...   \n",
      "508            1260               10200               3240            0  ...   \n",
      "509            1320                7500               5100            4  ...   \n",
      "510            1860               10140               5100            5  ...   \n",
      "511             420                8820               4320            7  ...   \n",
      "\n",
      "     hr_average  hr_min  hr_max  rr_average  rr_min  rr_max  \\\n",
      "351          69      57      83          16      12      25   \n",
      "352          73      63      82          16      12      22   \n",
      "353          73      58      84          17       9      22   \n",
      "354          72      64      80          16      11      24   \n",
      "355          72      60      85          16      12      21   \n",
      "..          ...     ...     ...         ...     ...     ...   \n",
      "507          63      51      82          14       9      23   \n",
      "508          63      51      76          14      10      21   \n",
      "509          64      52      84          15      10      21   \n",
      "510          63      52      84          14      10      21   \n",
      "511          62      52      79          15       9      23   \n",
      "\n",
      "     breathing_disturbances_intensity  snoring  snoringepisodecount  \\\n",
      "351                                18     8880                   16   \n",
      "352                                20     8280                   16   \n",
      "353                                17     8400                    7   \n",
      "354                                20    11400                   11   \n",
      "355                                14     5280                    5   \n",
      "..                                ...      ...                  ...   \n",
      "507                                20     7020                   14   \n",
      "508                                29     8940                   16   \n",
      "509                                24     8700                   13   \n",
      "510                                22    10200                   15   \n",
      "511                                17     8940                   12   \n",
      "\n",
      "     sleep_score  \n",
      "351           83  \n",
      "352           82  \n",
      "353           53  \n",
      "354           82  \n",
      "355           60  \n",
      "..           ...  \n",
      "507           56  \n",
      "508           74  \n",
      "509           45  \n",
      "510           56  \n",
      "511           56  \n",
      "\n",
      "[503 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "- label 데이터와 sleep 데이터에서 사용자별 기록된 날짜가 다름\n",
    "- 공통으로 기록된 날짜만 산출\n",
    "'''\n",
    "\n",
    "combined_results = pd.DataFrame()\n",
    "\n",
    "# 사용자 ID 설정 (user01 ~ user30)\n",
    "user_ids = [f'user{i:02d}' for i in range(1, 31)]\n",
    "\n",
    "for user_id in user_ids:\n",
    "    # df_label에서 사용자의 'date' 데이터 선택\n",
    "    user_dates = df_label[df_label['subject_id'] == user_id]['date']\n",
    "    \n",
    "    # df_user_sleep에서 해당 사용자의 데이터 선택\n",
    "    user_data = df_user_sleep[df_user_sleep['userId'] == user_id]\n",
    "    \n",
    "    # 각 사용자별 label 데이터 와 sleep 데이터의 공통 날짜 산출\n",
    "    common_dates = np.intersect1d(user_data['date'], user_dates)\n",
    "    \n",
    "    # 공통 날짜를 가진 데이터만 필터링\n",
    "    filtered_data = user_data[user_data['date'].isin(common_dates)]\n",
    "    \n",
    "    # 행 방향으로 모든 결과를 합침\n",
    "    combined_results = pd.concat([combined_results, filtered_data], axis=0)\n",
    "\n",
    "# 결과 출력\n",
    "print(combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_results.rename(columns={'userId': 'subject_id'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_label = pd.merge(combined_results[['subject_id', 'date']], df_label, on=['subject_id', 'date'], how='inner')\n",
    "\n",
    "# 결과 출력\n",
    "y = filtered_label[['S3','S4']]\n",
    "x = combined_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test data setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.drop(columns=['subject_id','timezone'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['date'] = pd.to_datetime(x['date'])\n",
    "x['date'] = x['date'].values.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_scale = ['date', 'startDt', 'endDt','lastUpdate']\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "# sc = StandardScaler()\n",
    "\n",
    "# 스케일링 적용\n",
    "x[columns_to_scale] = mms.fit_transform(x[columns_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>startDt</th>\n",
       "      <th>endDt</th>\n",
       "      <th>lastUpdate</th>\n",
       "      <th>wakeupduration</th>\n",
       "      <th>lightsleepduration</th>\n",
       "      <th>deepsleepduration</th>\n",
       "      <th>wakeupcount</th>\n",
       "      <th>durationtosleep</th>\n",
       "      <th>remsleepduration</th>\n",
       "      <th>...</th>\n",
       "      <th>hr_average</th>\n",
       "      <th>hr_min</th>\n",
       "      <th>hr_max</th>\n",
       "      <th>rr_average</th>\n",
       "      <th>rr_min</th>\n",
       "      <th>rr_max</th>\n",
       "      <th>breathing_disturbances_intensity</th>\n",
       "      <th>snoring</th>\n",
       "      <th>snoringepisodecount</th>\n",
       "      <th>sleep_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.028391</td>\n",
       "      <td>0.027451</td>\n",
       "      <td>0.027452</td>\n",
       "      <td>3240</td>\n",
       "      <td>11700</td>\n",
       "      <td>6120</td>\n",
       "      <td>1</td>\n",
       "      <td>1980</td>\n",
       "      <td>7500</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>57</td>\n",
       "      <td>83</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>8880</td>\n",
       "      <td>16</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.057256</td>\n",
       "      <td>0.055195</td>\n",
       "      <td>0.053423</td>\n",
       "      <td>1140</td>\n",
       "      <td>9660</td>\n",
       "      <td>6840</td>\n",
       "      <td>0</td>\n",
       "      <td>1140</td>\n",
       "      <td>7140</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>8280</td>\n",
       "      <td>16</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0.078947</td>\n",
       "      <td>0.084828</td>\n",
       "      <td>0.082592</td>\n",
       "      <td>0.080363</td>\n",
       "      <td>2640</td>\n",
       "      <td>6360</td>\n",
       "      <td>7020</td>\n",
       "      <td>3</td>\n",
       "      <td>1680</td>\n",
       "      <td>7260</td>\n",
       "      <td>...</td>\n",
       "      <td>73</td>\n",
       "      <td>58</td>\n",
       "      <td>84</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>8400</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.105263</td>\n",
       "      <td>0.110085</td>\n",
       "      <td>0.108928</td>\n",
       "      <td>0.106789</td>\n",
       "      <td>1560</td>\n",
       "      <td>9360</td>\n",
       "      <td>10140</td>\n",
       "      <td>1</td>\n",
       "      <td>1500</td>\n",
       "      <td>6000</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>64</td>\n",
       "      <td>80</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>11400</td>\n",
       "      <td>11</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.137947</td>\n",
       "      <td>0.135466</td>\n",
       "      <td>0.133290</td>\n",
       "      <td>1260</td>\n",
       "      <td>8580</td>\n",
       "      <td>8220</td>\n",
       "      <td>0</td>\n",
       "      <td>1260</td>\n",
       "      <td>4560</td>\n",
       "      <td>...</td>\n",
       "      <td>72</td>\n",
       "      <td>60</td>\n",
       "      <td>85</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>5280</td>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.605474</td>\n",
       "      <td>0.605318</td>\n",
       "      <td>0.603090</td>\n",
       "      <td>3780</td>\n",
       "      <td>11340</td>\n",
       "      <td>4200</td>\n",
       "      <td>2</td>\n",
       "      <td>2520</td>\n",
       "      <td>6420</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>51</td>\n",
       "      <td>82</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>20</td>\n",
       "      <td>7020</td>\n",
       "      <td>14</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631970</td>\n",
       "      <td>0.631618</td>\n",
       "      <td>0.629413</td>\n",
       "      <td>1260</td>\n",
       "      <td>10200</td>\n",
       "      <td>3240</td>\n",
       "      <td>0</td>\n",
       "      <td>1260</td>\n",
       "      <td>10140</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>51</td>\n",
       "      <td>76</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>8940</td>\n",
       "      <td>16</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.658138</td>\n",
       "      <td>0.656566</td>\n",
       "      <td>0.654444</td>\n",
       "      <td>1320</td>\n",
       "      <td>7500</td>\n",
       "      <td>5100</td>\n",
       "      <td>4</td>\n",
       "      <td>600</td>\n",
       "      <td>6300</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>52</td>\n",
       "      <td>84</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>8700</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.658138</td>\n",
       "      <td>0.657937</td>\n",
       "      <td>0.655707</td>\n",
       "      <td>1860</td>\n",
       "      <td>10140</td>\n",
       "      <td>5100</td>\n",
       "      <td>5</td>\n",
       "      <td>600</td>\n",
       "      <td>6300</td>\n",
       "      <td>...</td>\n",
       "      <td>63</td>\n",
       "      <td>52</td>\n",
       "      <td>84</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>10200</td>\n",
       "      <td>15</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.685290</td>\n",
       "      <td>0.684255</td>\n",
       "      <td>0.682041</td>\n",
       "      <td>420</td>\n",
       "      <td>8820</td>\n",
       "      <td>4320</td>\n",
       "      <td>7</td>\n",
       "      <td>240</td>\n",
       "      <td>7680</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>52</td>\n",
       "      <td>79</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>23</td>\n",
       "      <td>17</td>\n",
       "      <td>8940</td>\n",
       "      <td>12</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   startDt     endDt  lastUpdate  wakeupduration  \\\n",
       "351  0.026316  0.028391  0.027451    0.027452            3240   \n",
       "352  0.052632  0.057256  0.055195    0.053423            1140   \n",
       "353  0.078947  0.084828  0.082592    0.080363            2640   \n",
       "354  0.105263  0.110085  0.108928    0.106789            1560   \n",
       "355  0.131579  0.137947  0.135466    0.133290            1260   \n",
       "..        ...       ...       ...         ...             ...   \n",
       "507  0.605263  0.605474  0.605318    0.603090            3780   \n",
       "508  0.631579  0.631970  0.631618    0.629413            1260   \n",
       "509  0.657895  0.658138  0.656566    0.654444            1320   \n",
       "510  0.657895  0.658138  0.657937    0.655707            1860   \n",
       "511  0.684211  0.685290  0.684255    0.682041             420   \n",
       "\n",
       "     lightsleepduration  deepsleepduration  wakeupcount  durationtosleep  \\\n",
       "351               11700               6120            1             1980   \n",
       "352                9660               6840            0             1140   \n",
       "353                6360               7020            3             1680   \n",
       "354                9360              10140            1             1500   \n",
       "355                8580               8220            0             1260   \n",
       "..                  ...                ...          ...              ...   \n",
       "507               11340               4200            2             2520   \n",
       "508               10200               3240            0             1260   \n",
       "509                7500               5100            4              600   \n",
       "510               10140               5100            5              600   \n",
       "511                8820               4320            7              240   \n",
       "\n",
       "     remsleepduration  ...  hr_average  hr_min  hr_max  rr_average  rr_min  \\\n",
       "351              7500  ...          69      57      83          16      12   \n",
       "352              7140  ...          73      63      82          16      12   \n",
       "353              7260  ...          73      58      84          17       9   \n",
       "354              6000  ...          72      64      80          16      11   \n",
       "355              4560  ...          72      60      85          16      12   \n",
       "..                ...  ...         ...     ...     ...         ...     ...   \n",
       "507              6420  ...          63      51      82          14       9   \n",
       "508             10140  ...          63      51      76          14      10   \n",
       "509              6300  ...          64      52      84          15      10   \n",
       "510              6300  ...          63      52      84          14      10   \n",
       "511              7680  ...          62      52      79          15       9   \n",
       "\n",
       "     rr_max  breathing_disturbances_intensity  snoring  snoringepisodecount  \\\n",
       "351      25                                18     8880                   16   \n",
       "352      22                                20     8280                   16   \n",
       "353      22                                17     8400                    7   \n",
       "354      24                                20    11400                   11   \n",
       "355      21                                14     5280                    5   \n",
       "..      ...                               ...      ...                  ...   \n",
       "507      23                                20     7020                   14   \n",
       "508      21                                29     8940                   16   \n",
       "509      21                                24     8700                   13   \n",
       "510      21                                22    10200                   15   \n",
       "511      23                                17     8940                   12   \n",
       "\n",
       "     sleep_score  \n",
       "351           83  \n",
       "352           82  \n",
       "353           53  \n",
       "354           82  \n",
       "355           60  \n",
       "..           ...  \n",
       "507           56  \n",
       "508           74  \n",
       "509           45  \n",
       "510           56  \n",
       "511           56  \n",
       "\n",
       "[503 rows x 21 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   S3  S4\n",
       "0   1   1\n",
       "1   1   1\n",
       "2   1   1\n",
       "3   1   1\n",
       "4   0   1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 503 entries, 351 to 511\n",
      "Data columns (total 21 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   date                              503 non-null    float64\n",
      " 1   startDt                           503 non-null    float64\n",
      " 2   endDt                             503 non-null    float64\n",
      " 3   lastUpdate                        503 non-null    float64\n",
      " 4   wakeupduration                    503 non-null    int64  \n",
      " 5   lightsleepduration                503 non-null    int64  \n",
      " 6   deepsleepduration                 503 non-null    int64  \n",
      " 7   wakeupcount                       503 non-null    int64  \n",
      " 8   durationtosleep                   503 non-null    int64  \n",
      " 9   remsleepduration                  503 non-null    int64  \n",
      " 10  durationtowakeup                  503 non-null    int64  \n",
      " 11  hr_average                        503 non-null    int64  \n",
      " 12  hr_min                            503 non-null    int64  \n",
      " 13  hr_max                            503 non-null    int64  \n",
      " 14  rr_average                        503 non-null    int64  \n",
      " 15  rr_min                            503 non-null    int64  \n",
      " 16  rr_max                            503 non-null    int64  \n",
      " 17  breathing_disturbances_intensity  503 non-null    int64  \n",
      " 18  snoring                           503 non-null    int64  \n",
      " 19  snoringepisodecount               503 non-null    int64  \n",
      " 20  sleep_score                       503 non-null    int64  \n",
      "dtypes: float64(4), int64(17)\n",
      "memory usage: 86.5 KB\n"
     ]
    }
   ],
   "source": [
    "x.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "lscores = []\n",
    "\n",
    "def result(model, model_reg):\n",
    "    predicciones = model_reg.predict(X_test)\n",
    "    y_train_pred = cross_val_predict(model_reg, X_train, y_train, cv=3)\n",
    "    lscores.append({\n",
    "        \"name\" : model,\n",
    "        \"f1\" : round(f1_score(y_train, y_train_pred, average=\"micro\"), 4),\n",
    "        \"accuracy\" : round(accuracy_score(y_train, y_train_pred), 4),\n",
    "        \"precission\" : round(precision_score(y_train, y_train_pred, average=\"micro\"), 4),\n",
    "        \"recall\" : round(recall_score(y_train, y_train_pred, average=\"micro\"), 4)\n",
    "    })\n",
    "\n",
    "def roc_graph(models):\n",
    "    plt.figure(figsize=(10,8))\n",
    "    for i, (name, model) in enumerate(models.items()):\n",
    "        y_scores = cross_val_predict(model, X_train, y_train, cv=3, method=\"predict_proba\")\n",
    "        lscores[i][\"roc_auc_score\"] = round(roc_auc_score(y_train, y_scores, multi_class=\"ovr\"), 4)\n",
    "        y_scores = y_scores[:,1]\n",
    "        fpr, tpr, _ = roc_curve(y_train, y_scores, pos_label=1, drop_intermediate=True)\n",
    "        plt.plot(fpr, tpr, label=name)\n",
    "    \n",
    "    plt.title(\"ROC curve\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier # multi target classifier 적용을 위한 라이브러리\n",
    "\n",
    "models = {\n",
    "    \"SGDClassifier\": MultiOutputClassifier(SGDClassifier(loss=\"log_loss\")),\n",
    "    \"Logistic Regression\": MultiOutputClassifier(LogisticRegression(solver=\"lbfgs\", max_iter=10000)),\n",
    "    \"Decision Tree\": MultiOutputClassifier(DecisionTreeClassifier()),\n",
    "    \"Random Forest\": MultiOutputClassifier(RandomForestClassifier()),\n",
    "    \"SVM\": MultiOutputClassifier(SVC(probability=True)),\n",
    "    \n",
    "    \"Gradient Boosting\": MultiOutputClassifier(GradientBoostingClassifier()),\n",
    "    \"XGBoost\": MultiOutputClassifier(XGBClassifier(use_label_encoder=False, eval_metric='logloss')),\n",
    "    \"AdaBoost\": MultiOutputClassifier(AdaBoostClassifier(algorithm=\"SAMME\")),\n",
    "    \"Naive Bayes\": MultiOutputClassifier(GaussianNB()),\n",
    "    \"MLP Neural Network\": MultiOutputClassifier(MLPClassifier(max_iter=10000)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier(estimator=SGDClassifier(loss='log_loss'))\n",
      "MultiOutputClassifier(estimator=LogisticRegression(max_iter=10000))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier(estimator=DecisionTreeClassifier())\n",
      "MultiOutputClassifier(estimator=RandomForestClassifier())\n",
      "MultiOutputClassifier(estimator=SVC(probability=True))\n",
      "MultiOutputClassifier(estimator=GradientBoostingClassifier())\n",
      "MultiOutputClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
      "                                              callbacks=None,\n",
      "                                              colsample_bylevel=None,\n",
      "                                              colsample_bynode=None,\n",
      "                                              colsample_bytree=None,\n",
      "                                              early_stopping_rounds=None,\n",
      "                                              enable_categorical=False,\n",
      "                                              eval_metric='logloss',\n",
      "                                              feature_types=None, gamma=None,\n",
      "                                              gpu_id=None, grow_policy=None,\n",
      "                                              importance_type=None,\n",
      "                                              interaction_constraints=None,\n",
      "                                              learning_rate=None, max_bin=None,\n",
      "                                              max_cat_threshold=None,\n",
      "                                              max_cat_to_onehot=None,\n",
      "                                              max_delta_step=None,\n",
      "                                              max_depth=None, max_leaves=None,\n",
      "                                              min_child_weight=None,\n",
      "                                              missing=nan,\n",
      "                                              monotone_constraints=None,\n",
      "                                              n_estimators=100, n_jobs=None,\n",
      "                                              num_parallel_tree=None,\n",
      "                                              predictor=None, random_state=None, ...))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "c:\\Users\\user\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiOutputClassifier(estimator=AdaBoostClassifier(algorithm='SAMME'))\n",
      "MultiOutputClassifier(estimator=GaussianNB())\n",
      "MultiOutputClassifier(estimator=MLPClassifier(max_iter=10000))\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(model)\n",
    "    model.fit(X_train, y_train)\n",
    "    result(name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precission</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.7331</td>\n",
       "      <td>0.3422</td>\n",
       "      <td>0.6739</td>\n",
       "      <td>0.8036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.7569</td>\n",
       "      <td>0.3979</td>\n",
       "      <td>0.6811</td>\n",
       "      <td>0.8517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.6941</td>\n",
       "      <td>0.3395</td>\n",
       "      <td>0.6948</td>\n",
       "      <td>0.6934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.7778</td>\n",
       "      <td>0.4377</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>0.8697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.7887</td>\n",
       "      <td>0.3926</td>\n",
       "      <td>0.6617</td>\n",
       "      <td>0.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.7528</td>\n",
       "      <td>0.4058</td>\n",
       "      <td>0.7019</td>\n",
       "      <td>0.8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.7535</td>\n",
       "      <td>0.3899</td>\n",
       "      <td>0.7031</td>\n",
       "      <td>0.8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>0.3634</td>\n",
       "      <td>0.6859</td>\n",
       "      <td>0.7876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>0.3501</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>0.7595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP Neural Network</td>\n",
       "      <td>0.6167</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>0.6621</td>\n",
       "      <td>0.5772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name      f1  accuracy  precission  recall\n",
       "0        SGDClassifier  0.7331    0.3422      0.6739  0.8036\n",
       "1  Logistic Regression  0.7569    0.3979      0.6811  0.8517\n",
       "2        Decision Tree  0.6941    0.3395      0.6948  0.6934\n",
       "3        Random Forest  0.7778    0.4377      0.7034  0.8697\n",
       "4                  SVM  0.7887    0.3926      0.6617  0.9760\n",
       "5    Gradient Boosting  0.7528    0.4058      0.7019  0.8116\n",
       "6              XGBoost  0.7535    0.3899      0.7031  0.8116\n",
       "7             AdaBoost  0.7332    0.3634      0.6859  0.7876\n",
       "8          Naive Bayes  0.7178    0.3501      0.6804  0.7595\n",
       "9   MLP Neural Network  0.6167    0.2838      0.6621  0.5772"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame(lscores)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier prediction : [[1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]]\n",
      "Logistic Regression prediction : [[1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "Decision Tree prediction : [[1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]]\n",
      "Random Forest prediction : [[1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]]\n",
      "SVM prediction : [[1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "Gradient Boosting prediction : [[1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "XGBoost prediction : [[1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]]\n",
      "AdaBoost prediction : [[1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]]\n",
      "Naive Bayes prediction : [[1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "MLP Neural Network prediction : [[0 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [1 0]\n",
      " [1 1]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [1 1]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 1]\n",
      " [1 1]\n",
      " [0 1]\n",
      " [0 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    predicciones = model.predict(X_test)\n",
    "    print(f'{name} prediction : {predicciones}')\n",
    "\n",
    "    # errores=0\n",
    "    # for i, prediccion in enumerate(predicciones):\n",
    "    #     if prediccion != list(y_test)[i]:\n",
    "    #         errores+=1\n",
    "    # print(f\"{name} Errors: {errores} in {len(X_test)} with: {round(errores/len(X_test)*100, 2)}% of error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optunaNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.13.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (2.0.25)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (4.66.2)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.11.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.0.1)\n",
      "Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "   ---------------------------------------- 380.1/380.1 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
      "   ---------------------------------------- 233.4/233.4 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
      "Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
      "   ---------------------------------------- 78.6/78.6 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: Mako, colorlog, alembic, optuna\n",
      "Successfully installed Mako-1.3.5 alembic-1.13.1 colorlog-6.8.2 optuna-3.6.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-06-05 21:58:22,638] A new study created in memory with name: no-name-4c5ab846-12c4-406c-8861-7e9098031f58\n",
      "[I 2024-06-05 21:58:23,050] Trial 0 finished with value: 0.376984126984127 and parameters: {'eta': 1.8939812492647512, 'max_depth': 6, 'learning_rate': 0.18718203768305255, 'n_estimators': 309, 'min_child_weight': 7, 'gamma': 0.5838951915931766, 'subsample': 0.7610968571189265, 'colsample_bytree': 0.46294608825277306, 'reg_alpha': 0.34094632614574305, 'reg_lambda': 0.13096140220504904}. Best is trial 0 with value: 0.376984126984127.\n",
      "[I 2024-06-05 21:58:23,396] Trial 1 finished with value: 0.34523809523809523 and parameters: {'eta': 1.6280124560953122, 'max_depth': 8, 'learning_rate': 0.26070364738961105, 'n_estimators': 327, 'min_child_weight': 8, 'gamma': 0.5914424981471, 'subsample': 0.9206366128808114, 'colsample_bytree': 0.48162618609146896, 'reg_alpha': 0.5066659809776826, 'reg_lambda': 0.3866025139186137}. Best is trial 1 with value: 0.34523809523809523.\n",
      "[I 2024-06-05 21:58:24,066] Trial 2 finished with value: 0.3412698412698413 and parameters: {'eta': 1.401392603203395, 'max_depth': 7, 'learning_rate': 0.0520852620002141, 'n_estimators': 311, 'min_child_weight': 8, 'gamma': 0.6818597549051783, 'subsample': 0.8134137678666078, 'colsample_bytree': 0.519409657690311, 'reg_alpha': 0.3771001477823386, 'reg_lambda': 0.5130047220775646}. Best is trial 2 with value: 0.3412698412698413.\n",
      "[I 2024-06-05 21:58:24,505] Trial 3 finished with value: 0.376984126984127 and parameters: {'eta': 1.283393066668104, 'max_depth': 6, 'learning_rate': 0.14611120086122367, 'n_estimators': 364, 'min_child_weight': 9, 'gamma': 0.5757474914764835, 'subsample': 0.7922216951903437, 'colsample_bytree': 0.523407989316298, 'reg_alpha': 0.4885066022755031, 'reg_lambda': 0.4383566831327116}. Best is trial 2 with value: 0.3412698412698413.\n",
      "[I 2024-06-05 21:58:24,938] Trial 4 finished with value: 0.3333333333333333 and parameters: {'eta': 1.4552995778000395, 'max_depth': 7, 'learning_rate': 0.07146382619599999, 'n_estimators': 303, 'min_child_weight': 9, 'gamma': 0.7177581440701488, 'subsample': 0.8084038428705378, 'colsample_bytree': 0.4807623359258116, 'reg_alpha': 0.45705189476102454, 'reg_lambda': 0.31042610815134686}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:25,332] Trial 5 finished with value: 0.373015873015873 and parameters: {'eta': 1.9428093496245953, 'max_depth': 9, 'learning_rate': 0.10667719839648888, 'n_estimators': 444, 'min_child_weight': 9, 'gamma': 0.5708676418313483, 'subsample': 0.9408118475551046, 'colsample_bytree': 0.44434846364673064, 'reg_alpha': 0.33010008731062834, 'reg_lambda': 0.37033584734846703}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:25,667] Trial 6 finished with value: 0.36507936507936506 and parameters: {'eta': 1.9285357968855252, 'max_depth': 7, 'learning_rate': 0.44851085021492415, 'n_estimators': 344, 'min_child_weight': 8, 'gamma': 0.682497994483932, 'subsample': 0.8840953689949127, 'colsample_bytree': 0.5111001348481461, 'reg_alpha': 0.5797669087484959, 'reg_lambda': 0.40366778586097696}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:26,069] Trial 7 finished with value: 0.3611111111111111 and parameters: {'eta': 1.4336722575598615, 'max_depth': 7, 'learning_rate': 0.3013786011367511, 'n_estimators': 321, 'min_child_weight': 8, 'gamma': 0.6041668888998246, 'subsample': 0.7066691699872277, 'colsample_bytree': 0.5352935420536362, 'reg_alpha': 0.5866609574738649, 'reg_lambda': 0.33472517704394}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:26,365] Trial 8 finished with value: 0.38095238095238093 and parameters: {'eta': 1.4748256252945333, 'max_depth': 9, 'learning_rate': 0.4853225750513227, 'n_estimators': 315, 'min_child_weight': 9, 'gamma': 0.6434956515683256, 'subsample': 0.9088313810381677, 'colsample_bytree': 0.42337632692542704, 'reg_alpha': 0.374360481886291, 'reg_lambda': 0.41302674041966203}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:26,810] Trial 9 finished with value: 0.3650793650793651 and parameters: {'eta': 1.7128418631007396, 'max_depth': 8, 'learning_rate': 0.3872357160455326, 'n_estimators': 432, 'min_child_weight': 7, 'gamma': 0.7478897766920762, 'subsample': 0.8668574811266168, 'colsample_bytree': 0.458500343692862, 'reg_alpha': 0.329435169452173, 'reg_lambda': 0.16821129968197365}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:27,576] Trial 10 finished with value: 0.3492063492063492 and parameters: {'eta': 1.7513837434715056, 'max_depth': 6, 'learning_rate': 0.029543877234004194, 'n_estimators': 403, 'min_child_weight': 9, 'gamma': 0.5057261577015988, 'subsample': 0.7216671290376329, 'colsample_bytree': 0.4028911572798099, 'reg_alpha': 0.22923608758495229, 'reg_lambda': 0.027698473661709744}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:28,315] Trial 11 finished with value: 0.3412698412698413 and parameters: {'eta': 1.414344864148568, 'max_depth': 7, 'learning_rate': 0.02408976429792145, 'n_estimators': 359, 'min_child_weight': 8, 'gamma': 0.7403002140104176, 'subsample': 0.8178341291742616, 'colsample_bytree': 0.49642741629123754, 'reg_alpha': 0.45153023786857277, 'reg_lambda': 0.5568043586111447}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:28,722] Trial 12 finished with value: 0.3333333333333333 and parameters: {'eta': 1.2874855205347338, 'max_depth': 7, 'learning_rate': 0.09373047780086666, 'n_estimators': 303, 'min_child_weight': 7, 'gamma': 0.7978388161265948, 'subsample': 0.9849903572334906, 'colsample_bytree': 0.541318052398185, 'reg_alpha': 0.41482758115769724, 'reg_lambda': 0.5851595911471668}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:29,113] Trial 13 finished with value: 0.36507936507936506 and parameters: {'eta': 1.2521814665174735, 'max_depth': 8, 'learning_rate': 0.19358581504511693, 'n_estimators': 394, 'min_child_weight': 7, 'gamma': 0.7967327839578657, 'subsample': 0.9961467524977813, 'colsample_bytree': 0.5463734067468645, 'reg_alpha': 0.43676256213104675, 'reg_lambda': 0.24796972991370864}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:29,521] Trial 14 finished with value: 0.34523809523809523 and parameters: {'eta': 1.5401368097756731, 'max_depth': 7, 'learning_rate': 0.09826327646657704, 'n_estimators': 300, 'min_child_weight': 7, 'gamma': 0.7946955253165554, 'subsample': 0.982653438524089, 'colsample_bytree': 0.49480793336689133, 'reg_alpha': 0.2534193239631412, 'reg_lambda': 0.2495982787040562}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:29,981] Trial 15 finished with value: 0.3492063492063492 and parameters: {'eta': 1.319373383920662, 'max_depth': 8, 'learning_rate': 0.20399111800005199, 'n_estimators': 341, 'min_child_weight': 9, 'gamma': 0.7441990765679499, 'subsample': 0.8446922534856409, 'colsample_bytree': 0.5482096670472251, 'reg_alpha': 0.5276301415521867, 'reg_lambda': 0.5866331751090614}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:30,603] Trial 16 finished with value: 0.373015873015873 and parameters: {'eta': 1.5843312070975604, 'max_depth': 6, 'learning_rate': 0.09305467790219309, 'n_estimators': 340, 'min_child_weight': 7, 'gamma': 0.702705632937694, 'subsample': 0.7564531401191767, 'colsample_bytree': 0.4795735339665532, 'reg_alpha': 0.423760396903022, 'reg_lambda': 0.4798311511168033}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:31,079] Trial 17 finished with value: 0.373015873015873 and parameters: {'eta': 1.3467128486080588, 'max_depth': 7, 'learning_rate': 0.3475420030719095, 'n_estimators': 385, 'min_child_weight': 8, 'gamma': 0.7630805771721749, 'subsample': 0.9668269904132083, 'colsample_bytree': 0.43397586406903427, 'reg_alpha': 0.2875456155691648, 'reg_lambda': 0.06112380652705307}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:31,628] Trial 18 finished with value: 0.35317460317460314 and parameters: {'eta': 1.4683137821074586, 'max_depth': 8, 'learning_rate': 0.15103421913990817, 'n_estimators': 301, 'min_child_weight': 9, 'gamma': 0.716556317193866, 'subsample': 0.8431775256916025, 'colsample_bytree': 0.5069259073087095, 'reg_alpha': 0.47287358623309494, 'reg_lambda': 0.24262958952667818}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:32,151] Trial 19 finished with value: 0.36904761904761907 and parameters: {'eta': 1.3440007700949084, 'max_depth': 6, 'learning_rate': 0.2576389304824128, 'n_estimators': 418, 'min_child_weight': 7, 'gamma': 0.6456377732726729, 'subsample': 0.7779925892799857, 'colsample_bytree': 0.4645202249991862, 'reg_alpha': 0.4103749220843667, 'reg_lambda': 0.3035372973723086}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:32,556] Trial 20 finished with value: 0.35317460317460314 and parameters: {'eta': 1.5262333483315322, 'max_depth': 7, 'learning_rate': 0.131673702159212, 'n_estimators': 329, 'min_child_weight': 8, 'gamma': 0.7734382361550465, 'subsample': 0.9544377016337596, 'colsample_bytree': 0.40088478181327714, 'reg_alpha': 0.552646552365274, 'reg_lambda': 0.49868374512909835}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:33,123] Trial 21 finished with value: 0.3412698412698413 and parameters: {'eta': 1.3836558912467012, 'max_depth': 7, 'learning_rate': 0.059339383423324926, 'n_estimators': 315, 'min_child_weight': 8, 'gamma': 0.6727942260683962, 'subsample': 0.816164007866443, 'colsample_bytree': 0.5297356204393384, 'reg_alpha': 0.3727227255782517, 'reg_lambda': 0.5296723918606345}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:33,745] Trial 22 finished with value: 0.35317460317460314 and parameters: {'eta': 1.3876360642391514, 'max_depth': 7, 'learning_rate': 0.05797066689326514, 'n_estimators': 301, 'min_child_weight': 7, 'gamma': 0.7132065411037009, 'subsample': 0.8189690170311534, 'colsample_bytree': 0.5174780530480387, 'reg_alpha': 0.37882109046864915, 'reg_lambda': 0.5795420340181975}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:34,325] Trial 23 finished with value: 0.3492063492063492 and parameters: {'eta': 1.506576654111015, 'max_depth': 7, 'learning_rate': 0.07669806824989614, 'n_estimators': 355, 'min_child_weight': 9, 'gamma': 0.6245291655836306, 'subsample': 0.8783289128296862, 'colsample_bytree': 0.5365880791589791, 'reg_alpha': 0.4549630912502023, 'reg_lambda': 0.4731839615613952}. Best is trial 4 with value: 0.3333333333333333.\n",
      "[I 2024-06-05 21:58:34,932] Trial 24 finished with value: 0.32936507936507936 and parameters: {'eta': 1.2934009509566193, 'max_depth': 8, 'learning_rate': 0.02845743736762385, 'n_estimators': 334, 'min_child_weight': 8, 'gamma': 0.6762969225092168, 'subsample': 0.7914383412408894, 'colsample_bytree': 0.49731390792664953, 'reg_alpha': 0.4052776445413021, 'reg_lambda': 0.5213510320383542}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:35,394] Trial 25 finished with value: 0.3650793650793651 and parameters: {'eta': 1.250016136549952, 'max_depth': 8, 'learning_rate': 0.11833848770014209, 'n_estimators': 332, 'min_child_weight': 8, 'gamma': 0.7238206846071193, 'subsample': 0.7454059313789122, 'colsample_bytree': 0.4942804938541319, 'reg_alpha': 0.4031501486402618, 'reg_lambda': 0.5941398370790687}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:35,920] Trial 26 finished with value: 0.376984126984127 and parameters: {'eta': 1.3252542215158234, 'max_depth': 9, 'learning_rate': 0.1600804185199226, 'n_estimators': 320, 'min_child_weight': 8, 'gamma': 0.6635188718673086, 'subsample': 0.7962419602496532, 'colsample_bytree': 0.48519204081884953, 'reg_alpha': 0.5101625127332913, 'reg_lambda': 0.1825694904230266}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:36,519] Trial 27 finished with value: 0.38095238095238093 and parameters: {'eta': 1.6624813390253284, 'max_depth': 8, 'learning_rate': 0.2431678608343778, 'n_estimators': 372, 'min_child_weight': 9, 'gamma': 0.7818486161705136, 'subsample': 0.7336933903367419, 'colsample_bytree': 0.47093387019755906, 'reg_alpha': 0.29590930410663824, 'reg_lambda': 0.444013481157691}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:37,361] Trial 28 finished with value: 0.33333333333333337 and parameters: {'eta': 1.7943028029970165, 'max_depth': 8, 'learning_rate': 0.02023275665937986, 'n_estimators': 350, 'min_child_weight': 7, 'gamma': 0.6949082455772497, 'subsample': 0.7758713135570272, 'colsample_bytree': 0.5041428745534188, 'reg_alpha': 0.4776745105960336, 'reg_lambda': 0.5407046048601447}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:37,877] Trial 29 finished with value: 0.36904761904761907 and parameters: {'eta': 1.3064950497504682, 'max_depth': 6, 'learning_rate': 0.1828848105937581, 'n_estimators': 308, 'min_child_weight': 7, 'gamma': 0.5281114676777763, 'subsample': 0.9114221402544025, 'colsample_bytree': 0.4532428474631797, 'reg_alpha': 0.34407037099744525, 'reg_lambda': 0.1207367545084514}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:38,472] Trial 30 finished with value: 0.376984126984127 and parameters: {'eta': 1.8376954850845943, 'max_depth': 9, 'learning_rate': 0.08290547960849749, 'n_estimators': 334, 'min_child_weight': 8, 'gamma': 0.6246444298170403, 'subsample': 0.8583541767600085, 'colsample_bytree': 0.4709953474068189, 'reg_alpha': 0.4363405180770797, 'reg_lambda': 0.34906412426909805}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:39,198] Trial 31 finished with value: 0.3333333333333333 and parameters: {'eta': 1.8476801978484578, 'max_depth': 8, 'learning_rate': 0.020789550069171662, 'n_estimators': 352, 'min_child_weight': 7, 'gamma': 0.6925406177511351, 'subsample': 0.7747942019482177, 'colsample_bytree': 0.506688076787067, 'reg_alpha': 0.47042863401762747, 'reg_lambda': 0.5427667450612202}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:39,781] Trial 32 finished with value: 0.3492063492063492 and parameters: {'eta': 1.9825980862354526, 'max_depth': 8, 'learning_rate': 0.053464485107261275, 'n_estimators': 323, 'min_child_weight': 7, 'gamma': 0.7308411104992344, 'subsample': 0.7834701540016461, 'colsample_bytree': 0.4869010807864769, 'reg_alpha': 0.4616012485106682, 'reg_lambda': 0.5535954324178473}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:40,569] Trial 33 finished with value: 0.3492063492063492 and parameters: {'eta': 1.6156981331099958, 'max_depth': 8, 'learning_rate': 0.047607179956954335, 'n_estimators': 370, 'min_child_weight': 7, 'gamma': 0.69776434053573, 'subsample': 0.765081594021492, 'colsample_bytree': 0.4997556988289532, 'reg_alpha': 0.5061366941315282, 'reg_lambda': 0.5060583904471915}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:41,180] Trial 34 finished with value: 0.35714285714285715 and parameters: {'eta': 1.8258439771604908, 'max_depth': 8, 'learning_rate': 0.07888545341151962, 'n_estimators': 310, 'min_child_weight': 7, 'gamma': 0.6609057139469066, 'subsample': 0.832626043970559, 'colsample_bytree': 0.5135696053098587, 'reg_alpha': 0.3928060284947831, 'reg_lambda': 0.45452776403804995}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:41,781] Trial 35 finished with value: 0.376984126984127 and parameters: {'eta': 1.6837691493536202, 'max_depth': 7, 'learning_rate': 0.12114747798827674, 'n_estimators': 383, 'min_child_weight': 7, 'gamma': 0.760262916903837, 'subsample': 0.8012346108902502, 'colsample_bytree': 0.5270041426843991, 'reg_alpha': 0.5342342780926401, 'reg_lambda': 0.5164888860411196}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:42,711] Trial 36 finished with value: 0.35317460317460314 and parameters: {'eta': 1.578057623529858, 'max_depth': 9, 'learning_rate': 0.020763736332260745, 'n_estimators': 347, 'min_child_weight': 8, 'gamma': 0.6830778277580767, 'subsample': 0.7990844568554947, 'colsample_bytree': 0.48906757397926587, 'reg_alpha': 0.4931592092908343, 'reg_lambda': 0.5612321920888621}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:43,248] Trial 37 finished with value: 0.3888888888888889 and parameters: {'eta': 1.8765477755366804, 'max_depth': 7, 'learning_rate': 0.22116158156239846, 'n_estimators': 333, 'min_child_weight': 8, 'gamma': 0.6294410178543778, 'subsample': 0.74736913516695, 'colsample_bytree': 0.5389530002599174, 'reg_alpha': 0.3513162530846045, 'reg_lambda': 0.4203323602351952}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:43,895] Trial 38 finished with value: 0.3492063492063492 and parameters: {'eta': 1.440209030936513, 'max_depth': 8, 'learning_rate': 0.0473127532861323, 'n_estimators': 309, 'min_child_weight': 9, 'gamma': 0.5945894320390721, 'subsample': 0.8934816867043666, 'colsample_bytree': 0.5213338770600809, 'reg_alpha': 0.4261042768324638, 'reg_lambda': 0.3879720586563893}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:44,418] Trial 39 finished with value: 0.36904761904761907 and parameters: {'eta': 1.285567595595468, 'max_depth': 7, 'learning_rate': 0.10786609017108476, 'n_estimators': 364, 'min_child_weight': 7, 'gamma': 0.55686438324526, 'subsample': 0.935787633628543, 'colsample_bytree': 0.5089786691553195, 'reg_alpha': 0.4128516050734632, 'reg_lambda': 0.474498071856986}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:44,840] Trial 40 finished with value: 0.3888888888888889 and parameters: {'eta': 1.3566975113830022, 'max_depth': 8, 'learning_rate': 0.3019584321954093, 'n_estimators': 324, 'min_child_weight': 8, 'gamma': 0.6845250584914918, 'subsample': 0.8331471596452904, 'colsample_bytree': 0.4799513562154144, 'reg_alpha': 0.4447233485244336, 'reg_lambda': 0.30727703960008246}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:45,408] Trial 41 finished with value: 0.3571428571428571 and parameters: {'eta': 1.7924287397484058, 'max_depth': 8, 'learning_rate': 0.0350538775425036, 'n_estimators': 350, 'min_child_weight': 7, 'gamma': 0.6998530994140085, 'subsample': 0.7728921369666236, 'colsample_bytree': 0.5018920873177186, 'reg_alpha': 0.4748570100741082, 'reg_lambda': 0.5399970881703607}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:46,191] Trial 42 finished with value: 0.36904761904761907 and parameters: {'eta': 1.7476547572472116, 'max_depth': 8, 'learning_rate': 0.07565556097916634, 'n_estimators': 359, 'min_child_weight': 7, 'gamma': 0.6571747062976985, 'subsample': 0.7037602640136391, 'colsample_bytree': 0.5045676185421125, 'reg_alpha': 0.4889911246965958, 'reg_lambda': 0.5940140840357677}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:46,965] Trial 43 finished with value: 0.3412698412698413 and parameters: {'eta': 1.902733843107234, 'max_depth': 8, 'learning_rate': 0.027947477368144784, 'n_estimators': 351, 'min_child_weight': 7, 'gamma': 0.706879166147045, 'subsample': 0.7861796074466126, 'colsample_bytree': 0.5152517261044843, 'reg_alpha': 0.47074512354814235, 'reg_lambda': 0.532287485706822}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:47,564] Trial 44 finished with value: 0.36904761904761907 and parameters: {'eta': 1.8568204384602234, 'max_depth': 9, 'learning_rate': 0.07845697454338034, 'n_estimators': 317, 'min_child_weight': 7, 'gamma': 0.6874096735446942, 'subsample': 0.7297601835988791, 'colsample_bytree': 0.4758748044545795, 'reg_alpha': 0.38739076063619887, 'reg_lambda': 0.49996479340060984}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:48,083] Trial 45 finished with value: 0.3650793650793651 and parameters: {'eta': 1.9317134801464666, 'max_depth': 7, 'learning_rate': 0.16636917030201742, 'n_estimators': 338, 'min_child_weight': 7, 'gamma': 0.6717226955513436, 'subsample': 0.7637735761810265, 'colsample_bytree': 0.48959306789797197, 'reg_alpha': 0.5591029739447428, 'reg_lambda': 0.5687318001182734}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:48,513] Trial 46 finished with value: 0.36507936507936506 and parameters: {'eta': 1.777618660852019, 'max_depth': 8, 'learning_rate': 0.1347196144565491, 'n_estimators': 345, 'min_child_weight': 9, 'gamma': 0.7360843220173597, 'subsample': 0.8056109902362307, 'colsample_bytree': 0.5308134613020639, 'reg_alpha': 0.36325876328745155, 'reg_lambda': 0.36828351124007686}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:49,316] Trial 47 finished with value: 0.3492063492063492 and parameters: {'eta': 1.7094665617734421, 'max_depth': 7, 'learning_rate': 0.06294072892292424, 'n_estimators': 365, 'min_child_weight': 7, 'gamma': 0.6364826255171065, 'subsample': 0.8280448893058101, 'colsample_bytree': 0.5413657210422028, 'reg_alpha': 0.43142912834601177, 'reg_lambda': 0.4312003514666167}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:50,183] Trial 48 finished with value: 0.34523809523809523 and parameters: {'eta': 1.9939878683248282, 'max_depth': 8, 'learning_rate': 0.02045922362543237, 'n_estimators': 382, 'min_child_weight': 7, 'gamma': 0.6125529019186959, 'subsample': 0.7453385726967754, 'colsample_bytree': 0.4542167916509609, 'reg_alpha': 0.5095297625754314, 'reg_lambda': 0.538564933281524}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:50,884] Trial 49 finished with value: 0.373015873015873 and parameters: {'eta': 1.2808828003728867, 'max_depth': 7, 'learning_rate': 0.09878619248476589, 'n_estimators': 449, 'min_child_weight': 8, 'gamma': 0.7486443688848065, 'subsample': 0.7753557941461776, 'colsample_bytree': 0.5225765544169996, 'reg_alpha': 0.20373386356322162, 'reg_lambda': 0.46401835686825793}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:51,266] Trial 50 finished with value: 0.3849206349206349 and parameters: {'eta': 1.4369250506419937, 'max_depth': 8, 'learning_rate': 0.42148247287244844, 'n_estimators': 306, 'min_child_weight': 9, 'gamma': 0.7227017502387966, 'subsample': 0.7890517626996236, 'colsample_bytree': 0.4645485440500058, 'reg_alpha': 0.5284684561866679, 'reg_lambda': 0.2215894868795607}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:51,903] Trial 51 finished with value: 0.3373015873015873 and parameters: {'eta': 1.4022495753768702, 'max_depth': 7, 'learning_rate': 0.04099640780716619, 'n_estimators': 326, 'min_child_weight': 8, 'gamma': 0.6924749558096992, 'subsample': 0.8089662314625287, 'colsample_bytree': 0.4964374143402279, 'reg_alpha': 0.41473727770070845, 'reg_lambda': 0.5056371369051608}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:52,681] Trial 52 finished with value: 0.33333333333333337 and parameters: {'eta': 1.3722127622474183, 'max_depth': 7, 'learning_rate': 0.04443149452269056, 'n_estimators': 327, 'min_child_weight': 8, 'gamma': 0.6971715936902132, 'subsample': 0.8569149388343339, 'colsample_bytree': 0.4945736774730246, 'reg_alpha': 0.41920207734513826, 'reg_lambda': 0.4926958481503988}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:53,379] Trial 53 finished with value: 0.34523809523809523 and parameters: {'eta': 1.3744184409992404, 'max_depth': 7, 'learning_rate': 0.06307232871472, 'n_estimators': 339, 'min_child_weight': 8, 'gamma': 0.7093544134708799, 'subsample': 0.8549936503464668, 'colsample_bytree': 0.5113039921597888, 'reg_alpha': 0.45122481360345623, 'reg_lambda': 0.5703909436258278}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:53,997] Trial 54 finished with value: 0.3412698412698413 and parameters: {'eta': 1.3146756227236072, 'max_depth': 6, 'learning_rate': 0.03492265638614172, 'n_estimators': 315, 'min_child_weight': 8, 'gamma': 0.6732810761043463, 'subsample': 0.7166957707597792, 'colsample_bytree': 0.49190573892165307, 'reg_alpha': 0.31804187955654684, 'reg_lambda': 0.5552708319381763}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:54,419] Trial 55 finished with value: 0.3611111111111111 and parameters: {'eta': 1.486052528378122, 'max_depth': 7, 'learning_rate': 0.09648822348796057, 'n_estimators': 355, 'min_child_weight': 7, 'gamma': 0.6496386676419398, 'subsample': 0.9903931882122894, 'colsample_bytree': 0.48288328740801784, 'reg_alpha': 0.39997305603652694, 'reg_lambda': 0.5978498015952416}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:54,966] Trial 56 finished with value: 0.376984126984127 and parameters: {'eta': 1.285218659185329, 'max_depth': 7, 'learning_rate': 0.4945466544360507, 'n_estimators': 329, 'min_child_weight': 8, 'gamma': 0.7884679096949532, 'subsample': 0.9316867399291211, 'colsample_bytree': 0.502286387281335, 'reg_alpha': 0.47899058399881034, 'reg_lambda': 0.4898411885323801}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:55,516] Trial 57 finished with value: 0.34523809523809523 and parameters: {'eta': 1.3546301480247631, 'max_depth': 8, 'learning_rate': 0.06292481144250861, 'n_estimators': 303, 'min_child_weight': 9, 'gamma': 0.7626309494449383, 'subsample': 0.9497990833233768, 'colsample_bytree': 0.47182929511174404, 'reg_alpha': 0.4446900007008662, 'reg_lambda': 0.27409903043264827}. Best is trial 24 with value: 0.32936507936507936.\n",
      "[I 2024-06-05 21:58:56,071] Trial 58 finished with value: 0.32539682539682535 and parameters: {'eta': 1.4114528184377433, 'max_depth': 7, 'learning_rate': 0.04123800249710355, 'n_estimators': 314, 'min_child_weight': 8, 'gamma': 0.7187805818208935, 'subsample': 0.9763422726882779, 'colsample_bytree': 0.4098446805874757, 'reg_alpha': 0.46271392216195917, 'reg_lambda': 0.5289073701644847}. Best is trial 58 with value: 0.32539682539682535.\n",
      "[I 2024-06-05 21:58:56,511] Trial 59 finished with value: 0.36507936507936506 and parameters: {'eta': 1.5509967313222297, 'max_depth': 8, 'learning_rate': 0.1144285001132641, 'n_estimators': 313, 'min_child_weight': 7, 'gamma': 0.750895752640622, 'subsample': 0.967597119090569, 'colsample_bytree': 0.46112672689798584, 'reg_alpha': 0.4605416804402947, 'reg_lambda': 0.08065106589394372}. Best is trial 58 with value: 0.32539682539682535.\n",
      "[I 2024-06-05 21:58:57,106] Trial 60 finished with value: 0.3214285714285714 and parameters: {'eta': 1.4223915845004769, 'max_depth': 6, 'learning_rate': 0.021684776474925022, 'n_estimators': 319, 'min_child_weight': 8, 'gamma': 0.7312387368139835, 'subsample': 0.977355736373932, 'colsample_bytree': 0.4165905019246019, 'reg_alpha': 0.49336036607028866, 'reg_lambda': 0.522296059822283}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:58:57,640] Trial 61 finished with value: 0.32936507936507936 and parameters: {'eta': 1.462416461732297, 'max_depth': 6, 'learning_rate': 0.02412828546028284, 'n_estimators': 320, 'min_child_weight': 8, 'gamma': 0.7250899660567368, 'subsample': 0.9775453613380122, 'colsample_bytree': 0.42316146136470045, 'reg_alpha': 0.501982410183456, 'reg_lambda': 0.5318830083420307}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:58:58,249] Trial 62 finished with value: 0.3412698412698413 and parameters: {'eta': 1.4588417697252687, 'max_depth': 6, 'learning_rate': 0.03720108073611739, 'n_estimators': 317, 'min_child_weight': 8, 'gamma': 0.7251770950022642, 'subsample': 0.9739796432118938, 'colsample_bytree': 0.4140543603543973, 'reg_alpha': 0.4915772659105845, 'reg_lambda': 0.51893858768076}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:58:58,778] Trial 63 finished with value: 0.3373015873015873 and parameters: {'eta': 1.4233629738165519, 'max_depth': 6, 'learning_rate': 0.06623576644458118, 'n_estimators': 321, 'min_child_weight': 8, 'gamma': 0.773411762212789, 'subsample': 0.9820026898724155, 'colsample_bytree': 0.408319901666962, 'reg_alpha': 0.5022442819052635, 'reg_lambda': 0.5796377713035128}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:58:59,277] Trial 64 finished with value: 0.34523809523809523 and parameters: {'eta': 1.5049096376973998, 'max_depth': 6, 'learning_rate': 0.08928048600737111, 'n_estimators': 304, 'min_child_weight': 8, 'gamma': 0.7151089140150799, 'subsample': 0.9547319226036582, 'colsample_bytree': 0.4217892483657026, 'reg_alpha': 0.546075497309809, 'reg_lambda': 0.5258984273327393}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:58:59,877] Trial 65 finished with value: 0.3412698412698413 and parameters: {'eta': 1.4045731458947728, 'max_depth': 6, 'learning_rate': 0.049520152155116945, 'n_estimators': 300, 'min_child_weight': 8, 'gamma': 0.7358563986167385, 'subsample': 0.9998396495980356, 'colsample_bytree': 0.43001047279042937, 'reg_alpha': 0.4654977457082045, 'reg_lambda': 0.4000770585913467}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:00,533] Trial 66 finished with value: 0.32936507936507936 and parameters: {'eta': 1.3331472099289408, 'max_depth': 6, 'learning_rate': 0.03416937871010773, 'n_estimators': 312, 'min_child_weight': 8, 'gamma': 0.7226133559131269, 'subsample': 0.9786054548018144, 'colsample_bytree': 0.4177393851436799, 'reg_alpha': 0.5217081776186475, 'reg_lambda': 0.45542922923868734}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:01,030] Trial 67 finished with value: 0.3373015873015873 and parameters: {'eta': 1.3316592546112846, 'max_depth': 6, 'learning_rate': 0.13427363511912216, 'n_estimators': 311, 'min_child_weight': 8, 'gamma': 0.7441172695994948, 'subsample': 0.9852785891828121, 'colsample_bytree': 0.4175361045528484, 'reg_alpha': 0.5902078183926567, 'reg_lambda': 0.45800477818034635}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:01,515] Trial 68 finished with value: 0.34523809523809523 and parameters: {'eta': 1.4500465673182257, 'max_depth': 6, 'learning_rate': 0.07695212388739076, 'n_estimators': 320, 'min_child_weight': 8, 'gamma': 0.7752598229043829, 'subsample': 0.9618588195260083, 'colsample_bytree': 0.4383932014220767, 'reg_alpha': 0.5654249252272393, 'reg_lambda': 0.33405859469329935}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:01,883] Trial 69 finished with value: 0.36507936507936506 and parameters: {'eta': 1.2641040846014648, 'max_depth': 6, 'learning_rate': 0.30086138609545166, 'n_estimators': 307, 'min_child_weight': 8, 'gamma': 0.7285226246940788, 'subsample': 0.9781428837148559, 'colsample_bytree': 0.4254954182305431, 'reg_alpha': 0.5253284148679451, 'reg_lambda': 0.43581738263477726}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:02,706] Trial 70 finished with value: 0.32539682539682535 and parameters: {'eta': 1.3024001840253194, 'max_depth': 6, 'learning_rate': 0.03496469753668712, 'n_estimators': 418, 'min_child_weight': 8, 'gamma': 0.7977713318738863, 'subsample': 0.9471381842338071, 'colsample_bytree': 0.40753305588695926, 'reg_alpha': 0.5209952420178051, 'reg_lambda': 0.4818256040597169}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:03,412] Trial 71 finished with value: 0.33333333333333337 and parameters: {'eta': 1.2998029221978218, 'max_depth': 6, 'learning_rate': 0.03796215486131615, 'n_estimators': 411, 'min_child_weight': 8, 'gamma': 0.7952035113226452, 'subsample': 0.947092089714927, 'colsample_bytree': 0.4079525617877378, 'reg_alpha': 0.5229629562591784, 'reg_lambda': 0.4781858600968885}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:04,024] Trial 72 finished with value: 0.3253968253968254 and parameters: {'eta': 1.3411561817696451, 'max_depth': 6, 'learning_rate': 0.05168732138831962, 'n_estimators': 432, 'min_child_weight': 8, 'gamma': 0.7821971126768651, 'subsample': 0.9899694237331584, 'colsample_bytree': 0.40586232653698306, 'reg_alpha': 0.570566120656803, 'reg_lambda': 0.5610846527523292}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:04,595] Trial 73 finished with value: 0.3373015873015873 and parameters: {'eta': 1.336139499446803, 'max_depth': 6, 'learning_rate': 0.05530810159421892, 'n_estimators': 426, 'min_child_weight': 8, 'gamma': 0.7575526476731959, 'subsample': 0.9697170267573663, 'colsample_bytree': 0.40627452965900035, 'reg_alpha': 0.5694855593971493, 'reg_lambda': 0.5161152418769889}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:05,273] Trial 74 finished with value: 0.3412698412698413 and parameters: {'eta': 1.4809299854305522, 'max_depth': 6, 'learning_rate': 0.03313972338324725, 'n_estimators': 437, 'min_child_weight': 8, 'gamma': 0.7858025295327867, 'subsample': 0.9580194592379249, 'colsample_bytree': 0.4136090043036902, 'reg_alpha': 0.5428613886362864, 'reg_lambda': 0.5491111527306576}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:05,748] Trial 75 finished with value: 0.35317460317460314 and parameters: {'eta': 1.3906465774284356, 'max_depth': 6, 'learning_rate': 0.0710759800322518, 'n_estimators': 433, 'min_child_weight': 8, 'gamma': 0.7715399788727714, 'subsample': 0.9926097386484075, 'colsample_bytree': 0.4006644494147374, 'reg_alpha': 0.5151085654372501, 'reg_lambda': 0.48138686566202016}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:06,242] Trial 76 finished with value: 0.3611111111111111 and parameters: {'eta': 1.3649281933929336, 'max_depth': 6, 'learning_rate': 0.04936548311330244, 'n_estimators': 395, 'min_child_weight': 8, 'gamma': 0.7187367012884567, 'subsample': 0.9231918171634703, 'colsample_bytree': 0.4126992983695768, 'reg_alpha': 0.597614239067862, 'reg_lambda': 0.00846697117431866}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:06,968] Trial 77 finished with value: 0.3373015873015873 and parameters: {'eta': 1.3098992650094843, 'max_depth': 6, 'learning_rate': 0.03021059784321209, 'n_estimators': 421, 'min_child_weight': 8, 'gamma': 0.7538616269454991, 'subsample': 0.9632797415836606, 'colsample_bytree': 0.4195802570364497, 'reg_alpha': 0.4996261471590902, 'reg_lambda': 0.4477094917187971}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:07,524] Trial 78 finished with value: 0.3333333333333333 and parameters: {'eta': 1.4207900019198267, 'max_depth': 6, 'learning_rate': 0.054461969475289154, 'n_estimators': 443, 'min_child_weight': 8, 'gamma': 0.7393440209323422, 'subsample': 0.9749493364213396, 'colsample_bytree': 0.42704854606183357, 'reg_alpha': 0.578492126544629, 'reg_lambda': 0.40942484490437125}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:08,143] Trial 79 finished with value: 0.3571428571428571 and parameters: {'eta': 1.3414698684394417, 'max_depth': 6, 'learning_rate': 0.08840794933244467, 'n_estimators': 408, 'min_child_weight': 8, 'gamma': 0.706475319335997, 'subsample': 0.9429790440091688, 'colsample_bytree': 0.43518306893265607, 'reg_alpha': 0.543831796386172, 'reg_lambda': 0.5093096228483139}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:08,866] Trial 80 finished with value: 0.3253968253968254 and parameters: {'eta': 1.2655024308958953, 'max_depth': 6, 'learning_rate': 0.0209671022409139, 'n_estimators': 313, 'min_child_weight': 8, 'gamma': 0.7690650538602418, 'subsample': 0.9868419185176982, 'colsample_bytree': 0.4045476657430452, 'reg_alpha': 0.4807472301229703, 'reg_lambda': 0.5650993547080834}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:09,481] Trial 81 finished with value: 0.32936507936507936 and parameters: {'eta': 1.271363762812941, 'max_depth': 6, 'learning_rate': 0.02012760354303824, 'n_estimators': 313, 'min_child_weight': 8, 'gamma': 0.7806080404016624, 'subsample': 0.9917191644523129, 'colsample_bytree': 0.41065253324058715, 'reg_alpha': 0.4826196443614967, 'reg_lambda': 0.5718508720776952}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:10,223] Trial 82 finished with value: 0.3412698412698413 and parameters: {'eta': 1.2677520126674557, 'max_depth': 6, 'learning_rate': 0.021674409738201138, 'n_estimators': 317, 'min_child_weight': 8, 'gamma': 0.780282389982503, 'subsample': 0.9897346673263517, 'colsample_bytree': 0.41024249945302377, 'reg_alpha': 0.5180668461531723, 'reg_lambda': 0.5707058178467318}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:10,813] Trial 83 finished with value: 0.3412698412698413 and parameters: {'eta': 1.2516153312015976, 'max_depth': 6, 'learning_rate': 0.0448099980167183, 'n_estimators': 312, 'min_child_weight': 8, 'gamma': 0.7901996948616182, 'subsample': 0.9955449784611607, 'colsample_bytree': 0.40370774611260296, 'reg_alpha': 0.4835873967357332, 'reg_lambda': 0.5577598042962244}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:11,390] Trial 84 finished with value: 0.33333333333333337 and parameters: {'eta': 1.2965741900380132, 'max_depth': 6, 'learning_rate': 0.03133527009143788, 'n_estimators': 320, 'min_child_weight': 8, 'gamma': 0.7990928191913759, 'subsample': 0.9841648362382444, 'colsample_bytree': 0.4167826598810541, 'reg_alpha': 0.4966039781140492, 'reg_lambda': 0.5808232010641922}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:12,023] Trial 85 finished with value: 0.34523809523809523 and parameters: {'eta': 1.3212444815681874, 'max_depth': 6, 'learning_rate': 0.06636214194788152, 'n_estimators': 334, 'min_child_weight': 8, 'gamma': 0.7671498218157756, 'subsample': 0.9732488925405254, 'colsample_bytree': 0.40495885902364415, 'reg_alpha': 0.5354251748170826, 'reg_lambda': 0.5303127644314474}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:12,523] Trial 86 finished with value: 0.3253968253968254 and parameters: {'eta': 1.2782643520096961, 'max_depth': 6, 'learning_rate': 0.03979424140784171, 'n_estimators': 323, 'min_child_weight': 8, 'gamma': 0.7838118223119653, 'subsample': 0.9811562860121635, 'colsample_bytree': 0.41677076805892554, 'reg_alpha': 0.48596140474290644, 'reg_lambda': 0.539721477202968}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:13,161] Trial 87 finished with value: 0.3373015873015873 and parameters: {'eta': 1.3530565903080713, 'max_depth': 6, 'learning_rate': 0.04320615624433886, 'n_estimators': 330, 'min_child_weight': 8, 'gamma': 0.764504232380352, 'subsample': 0.9794380119616863, 'colsample_bytree': 0.44261134029375926, 'reg_alpha': 0.5095713494373478, 'reg_lambda': 0.5447568618579703}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:13,612] Trial 88 finished with value: 0.373015873015873 and parameters: {'eta': 1.3890633559746197, 'max_depth': 6, 'learning_rate': 0.36373059812090297, 'n_estimators': 323, 'min_child_weight': 8, 'gamma': 0.7915343801920731, 'subsample': 0.9643157124589121, 'colsample_bytree': 0.4291851899101443, 'reg_alpha': 0.5539242476620422, 'reg_lambda': 0.4903058467840697}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:14,236] Trial 89 finished with value: 0.34523809523809523 and parameters: {'eta': 1.2988519885228558, 'max_depth': 6, 'learning_rate': 0.05618648084703591, 'n_estimators': 426, 'min_child_weight': 8, 'gamma': 0.7332482985273869, 'subsample': 0.9981476230540594, 'colsample_bytree': 0.4223788793841894, 'reg_alpha': 0.5370042866729444, 'reg_lambda': 0.5162475019944817}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:14,709] Trial 90 finished with value: 0.3492063492063492 and parameters: {'eta': 1.3236461304016172, 'max_depth': 6, 'learning_rate': 0.10462002973896814, 'n_estimators': 336, 'min_child_weight': 8, 'gamma': 0.7438291883070811, 'subsample': 0.9534456938538356, 'colsample_bytree': 0.41694219941496247, 'reg_alpha': 0.44609491223117925, 'reg_lambda': 0.5288000380392135}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:15,234] Trial 91 finished with value: 0.3373015873015873 and parameters: {'eta': 1.2731224795532265, 'max_depth': 6, 'learning_rate': 0.022414223396231395, 'n_estimators': 325, 'min_child_weight': 8, 'gamma': 0.781206265500355, 'subsample': 0.99140618643577, 'colsample_bytree': 0.41085051619002183, 'reg_alpha': 0.4786827678472957, 'reg_lambda': 0.5677963970405795}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:15,824] Trial 92 finished with value: 0.32936507936507936 and parameters: {'eta': 1.26222399573935, 'max_depth': 6, 'learning_rate': 0.031221577314521517, 'n_estimators': 309, 'min_child_weight': 8, 'gamma': 0.7798724745971668, 'subsample': 0.9871919775984808, 'colsample_bytree': 0.400735220671857, 'reg_alpha': 0.4851857964215033, 'reg_lambda': 0.5489829243488833}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:16,380] Trial 93 finished with value: 0.3373015873015873 and parameters: {'eta': 1.2827263934221265, 'max_depth': 6, 'learning_rate': 0.04129112405631644, 'n_estimators': 315, 'min_child_weight': 8, 'gamma': 0.756662270933609, 'subsample': 0.9706762291638327, 'colsample_bytree': 0.4053016807857128, 'reg_alpha': 0.49848443219773786, 'reg_lambda': 0.5979094334181565}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:17,138] Trial 94 finished with value: 0.32936507936507936 and parameters: {'eta': 1.3062592616448714, 'max_depth': 6, 'learning_rate': 0.020255363901002636, 'n_estimators': 313, 'min_child_weight': 8, 'gamma': 0.7717457653862556, 'subsample': 0.8978787251907587, 'colsample_bytree': 0.41432512473151395, 'reg_alpha': 0.46638635493945857, 'reg_lambda': 0.5028276810895581}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:17,523] Trial 95 finished with value: 0.376984126984127 and parameters: {'eta': 1.3389297059126215, 'max_depth': 6, 'learning_rate': 0.46587212568351605, 'n_estimators': 306, 'min_child_weight': 8, 'gamma': 0.7990617214237467, 'subsample': 0.9790183293869936, 'colsample_bytree': 0.42018953926030944, 'reg_alpha': 0.5160119173800553, 'reg_lambda': 0.46909005068091125}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:18,000] Trial 96 finished with value: 0.3571428571428571 and parameters: {'eta': 1.3717128273976786, 'max_depth': 6, 'learning_rate': 0.06913324670223087, 'n_estimators': 319, 'min_child_weight': 8, 'gamma': 0.7888484910860768, 'subsample': 0.933813387247112, 'colsample_bytree': 0.41074214754876526, 'reg_alpha': 0.45441133606823214, 'reg_lambda': 0.5833198188954244}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:18,441] Trial 97 finished with value: 0.34523809523809523 and parameters: {'eta': 1.293493619461765, 'max_depth': 6, 'learning_rate': 0.053514458403138405, 'n_estimators': 328, 'min_child_weight': 8, 'gamma': 0.7658315190195728, 'subsample': 0.9628296817507036, 'colsample_bytree': 0.4242570240819475, 'reg_alpha': 0.4887880311613359, 'reg_lambda': 0.5631248510985587}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:19,194] Trial 98 finished with value: 0.34523809523809523 and parameters: {'eta': 1.2698418152475779, 'max_depth': 6, 'learning_rate': 0.029166461717761005, 'n_estimators': 394, 'min_child_weight': 8, 'gamma': 0.784653251801209, 'subsample': 0.8707542574371786, 'colsample_bytree': 0.40822209765168027, 'reg_alpha': 0.4364026480436819, 'reg_lambda': 0.5370661056223511}. Best is trial 60 with value: 0.3214285714285714.\n",
      "[I 2024-06-05 21:59:19,668] Trial 99 finished with value: 0.33333333333333337 and parameters: {'eta': 1.3223861049522236, 'max_depth': 6, 'learning_rate': 0.08622565797492455, 'n_estimators': 343, 'min_child_weight': 8, 'gamma': 0.749527015023587, 'subsample': 0.9843638683712317, 'colsample_bytree': 0.4321678194652736, 'reg_alpha': 0.5033382764085811, 'reg_lambda': 0.5210391448566444}. Best is trial 60 with value: 0.3214285714285714.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eta': 1.4223915845004769,\n",
       " 'max_depth': 6,\n",
       " 'learning_rate': 0.021684776474925022,\n",
       " 'n_estimators': 319,\n",
       " 'min_child_weight': 8,\n",
       " 'gamma': 0.7312387368139835,\n",
       " 'subsample': 0.977355736373932,\n",
       " 'colsample_bytree': 0.4165905019246019,\n",
       " 'reg_alpha': 0.49336036607028866,\n",
       " 'reg_lambda': 0.522296059822283}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수정 중\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def objective(trial):\n",
    "   param = {\n",
    "       'tree_method':'hist',\n",
    "       #'criterion' : trial.suggest_categorical(\"criterion\", [\"gini\", \"entropy\"]),\n",
    "       'eta': trial.suggest_float('eta', 1.25, 2),\n",
    "       'max_depth': trial.suggest_int('max_depth', 6, 9),\n",
    "       'learning_rate': trial.suggest_float('learning_rate', 0.020, 0.5),\n",
    "       'n_estimators': trial.suggest_int('n_estimators', 300, 450),\n",
    "       'min_child_weight': trial.suggest_int('min_child_weight', 7, 9),\n",
    "       'gamma': trial.suggest_float('gamma', 0.5, 0.8),\n",
    "       'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "       'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.55),\n",
    "       'reg_alpha': trial.suggest_float('reg_alpha', 0.2, 0.6),\n",
    "       'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 0.6),\n",
    "   }\n",
    "\n",
    "   model = XGBClassifier(**param)\n",
    "#  model = XGBClassifier(**param)\n",
    "   model.fit(X_train, y_train)\n",
    "   y_pred = model.predict(X_test)\n",
    "   f1 = f1_score(y_test, y_pred, average='macro')\n",
    "   accuracy = accuracy_score(y_test, y_pred, average='macro')\n",
    "   precisio = precision_score(y_test, y_pred, average='macro')\n",
    "   recall = recall_score(y_test, y_pred, average='macro')\n",
    "\n",
    "   return mean_squared_error(y_test, y_pred),\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3214285714285714\n",
      "Best hyperparameters: {'eta': 1.4223915845004769, 'max_depth': 6, 'learning_rate': 0.021684776474925022, 'n_estimators': 319, 'min_child_weight': 8, 'gamma': 0.7312387368139835, 'subsample': 0.977355736373932, 'colsample_bytree': 0.4165905019246019, 'reg_alpha': 0.49336036607028866, 'reg_lambda': 0.522296059822283}\n"
     ]
    }
   ],
   "source": [
    "trial = study.best_trial\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "markers",
         "name": "Objective Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.3373015873015873,
          0.3492063492063492,
          0.36507936507936506,
          0.3611111111111111,
          0.39285714285714285,
          0.31746031746031744,
          0.33333333333333337,
          0.31746031746031744,
          0.3492063492063492,
          0.3373015873015873,
          0.3650793650793651,
          0.35714285714285715,
          0.3492063492063492,
          0.35714285714285715,
          0.3492063492063492,
          0.32936507936507936,
          0.34523809523809523,
          0.36904761904761907,
          0.373015873015873,
          0.35317460317460314,
          0.3571428571428571,
          0.35317460317460314,
          0.35317460317460314,
          0.32936507936507936,
          0.3412698412698413,
          0.34523809523809523,
          0.3412698412698413,
          0.3492063492063492,
          0.34523809523809523,
          0.34523809523809523,
          0.32936507936507936,
          0.35317460317460314,
          0.3373015873015873,
          0.3412698412698413,
          0.3492063492063492,
          0.3611111111111111,
          0.34523809523809523,
          0.3412698412698413,
          0.35317460317460314,
          0.3333333333333333,
          0.36904761904761907,
          0.3253968253968254,
          0.32936507936507936,
          0.34523809523809523,
          0.3412698412698413,
          0.3373015873015873,
          0.3412698412698413,
          0.39285714285714285,
          0.32936507936507936,
          0.35714285714285715,
          0.34523809523809523,
          0.32936507936507936,
          0.33333333333333337,
          0.3492063492063492,
          0.3373015873015873,
          0.3373015873015873,
          0.3611111111111111,
          0.3492063492063492,
          0.3373015873015873,
          0.3412698412698413,
          0.32936507936507936,
          0.34523809523809523,
          0.3412698412698413,
          0.32936507936507936,
          0.34523809523809523,
          0.34523809523809523,
          0.35317460317460314,
          0.3650793650793651,
          0.36507936507936506,
          0.33333333333333337,
          0.34523809523809523,
          0.373015873015873,
          0.3412698412698413,
          0.3214285714285714,
          0.35317460317460314,
          0.35317460317460314,
          0.3373015873015873,
          0.33333333333333337,
          0.32936507936507936,
          0.34523809523809523,
          0.3373015873015873,
          0.36507936507936506,
          0.34523809523809523,
          0.3253968253968254,
          0.32936507936507936,
          0.35317460317460314,
          0.3650793650793651,
          0.36507936507936506,
          0.3412698412698413,
          0.3611111111111111,
          0.3373015873015873,
          0.376984126984127,
          0.35317460317460314,
          0.3373015873015873,
          0.3492063492063492,
          0.33333333333333337,
          0.3373015873015873,
          0.3373015873015873,
          0.3611111111111111,
          0.34523809523809523
         ]
        },
        {
         "mode": "lines",
         "name": "Best Value",
         "type": "scatter",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          0.3373015873015873,
          0.3373015873015873,
          0.3373015873015873,
          0.3373015873015873,
          0.3373015873015873,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744,
          0.31746031746031744
         ]
        },
        {
         "marker": {
          "color": "#cccccc"
         },
         "mode": "markers",
         "name": "Infeasible Trial",
         "showlegend": false,
         "type": "scatter",
         "x": [],
         "y": []
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Optimization History Plot"
        },
        "xaxis": {
         "title": {
          "text": "Trial"
         }
        },
        "yaxis": {
         "title": {
          "text": "Objective Value"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL - 코드 수정 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282, 21)\n"
     ]
    }
   ],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(x, y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# StandarScaler for removing data that is too different see \"Weight\" in this dataset\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_val = sc.fit_transform(X_val)\n",
    "X_test = sc.fit_transform(X_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DL model example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "num_classes = 2 # S3, S4\n",
    "\n",
    "# 모델 정의\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.stack = nn.Sequential(\n",
    "            nn.Linear(X_train.shape[1], 32),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes),\n",
    "            # nn.Softmax(dim=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.stack(x)\n",
    "\n",
    "model = NeuralNetwork()\n",
    "\n",
    "# 손실 함수 및 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "# 훈련 루프\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, n_epochs=700, patience=50):\n",
    "    best_loss = float('inf')\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        \n",
    "        # 검증 손실 계산\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        print(f'Epoch {epoch + 1} - Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "\n",
    "        # # early stopping\n",
    "        # if val_loss < best_loss:\n",
    "        #     best_loss = val_loss\n",
    "        #     torch.save(model.state_dict(), 'model/my_torch_model.pth')\n",
    "        #     early_stopping_counter = 0\n",
    "        # else:\n",
    "        #     early_stopping_counter += 1\n",
    "        #     if early_stopping_counter >= patience:\n",
    "        #         print(\"Early stopping triggered.\")\n",
    "        #         break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11180\\2022704914.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# X_train_np = X_train_numeric.values.astype(np.float32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my_train_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_val_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my_test_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "# X_train_np = X_train_numeric.values.astype(np.float32)\n",
    "y_train_np = y_train.values.astype(np.float32)\n",
    "y_val_np = y_val.values.astype(np.float32)\n",
    "y_test_np = y_test.values.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11180\\1510929663.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11180\\1510929663.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val = torch.tensor(X_val, dtype=torch.float32)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_11180\\1510929663.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val_np, dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# Create data loaders\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11180\\2891193064.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Save the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./model/torch_model_ep700.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11180\\490308529.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, n_epochs, patience)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1532\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1539\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11180\\490308529.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1532\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1539\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[misc]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1532\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1539\u001b[0m                 \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1543\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m   1543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1544\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1545\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[1;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[0;32m   1883\u001b[0m         \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"softmax\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1884\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1885\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1886\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1887\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), './model/torch_model_ep700.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.0316\n"
     ]
    }
   ],
   "source": [
    "# Load and evaluate the model using the test data\n",
    "model.load_state_dict(torch.load('./model/torch_model_ep700.pth'))\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = []\n",
    "# with torch.no_grad():\n",
    "#     outputs = []\n",
    "#     for inputs, labels in test_loader:\n",
    "#         outputs.append(model(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, preds = torch.max(outputs[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11180\\31441626.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "_, preds0 = torch.max(outputs[0], 1)\n",
    "_, preds1 = torch.max(outputs[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2979,  0.3285],\n",
       "        [-0.0634, -0.2568],\n",
       "        [-1.0328, -0.8654],\n",
       "        [-0.4197,  0.5527],\n",
       "        [-0.5957,  0.3472],\n",
       "        [-0.4240,  0.5928],\n",
       "        [-1.0050,  0.2877],\n",
       "        [-0.9856, -0.0297],\n",
       "        [-0.7264,  0.8510],\n",
       "        [-0.9878, -0.5184],\n",
       "        [-1.1781, -0.1177],\n",
       "        [-0.5249, -0.1338],\n",
       "        [ 0.1739,  0.8200],\n",
       "        [-0.1445,  0.3792],\n",
       "        [-0.4709, -0.7983],\n",
       "        [-1.3446, -1.4599],\n",
       "        [-1.0984,  1.1216],\n",
       "        [ 0.6810, -0.5938],\n",
       "        [-1.4285,  0.2711],\n",
       "        [-0.9706, -0.3931],\n",
       "        [-1.4500, -0.8228],\n",
       "        [ 0.0775, -0.2695],\n",
       "        [-0.2296, -0.4983],\n",
       "        [-0.2612, -0.3220],\n",
       "        [ 0.2392, -0.3585],\n",
       "        [ 0.0489,  0.0479],\n",
       "        [ 0.4062, -0.3668],\n",
       "        [-2.0415, -1.3659],\n",
       "        [-1.8899, -0.0319],\n",
       "        [-1.5624,  0.5418],\n",
       "        [-0.8080,  0.3701],\n",
       "        [-0.9419, -0.6289],\n",
       "        [-2.0424, -2.1964],\n",
       "        [ 0.3966, -0.1332],\n",
       "        [-0.1440,  0.1239],\n",
       "        [ 0.8838, -1.1144],\n",
       "        [-0.2047,  0.0270],\n",
       "        [ 1.0137, -1.0418],\n",
       "        [ 0.9012, -0.3937],\n",
       "        [-0.5148, -0.3536],\n",
       "        [-2.6630, -0.0339],\n",
       "        [-0.7487, -0.3644],\n",
       "        [-0.9130,  0.6760],\n",
       "        [-0.7306,  0.4941],\n",
       "        [ 0.3285, -0.6380],\n",
       "        [-2.0665, -1.6276],\n",
       "        [ 0.4798,  0.0201],\n",
       "        [-0.4233,  0.8418],\n",
       "        [-1.1495,  0.0833],\n",
       "        [-0.1218,  0.8801],\n",
       "        [ 0.0317, -1.0761],\n",
       "        [-0.9847,  0.8833],\n",
       "        [ 0.3596, -0.0936],\n",
       "        [-0.5893, -1.5024],\n",
       "        [-0.9380,  0.0270],\n",
       "        [-0.6542,  0.6131],\n",
       "        [-0.8422,  0.3804],\n",
       "        [-0.2185, -0.1895],\n",
       "        [-0.7490,  0.5351],\n",
       "        [-1.5452,  0.8654],\n",
       "        [ 1.5091, -1.0550],\n",
       "        [-0.0243, -0.0627]])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 1.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 0.],\n",
       "        [1., 1.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "max() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11180\\2681274808.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Converting probabilities to class labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Convert to numpy arrays for compatibility with sklearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: max() received an invalid combination of arguments - got (list, int), but expected one of:\n * (Tensor input, *, Tensor out)\n * (Tensor input, Tensor other, *, Tensor out)\n * (Tensor input, int dim, bool keepdim, *, tuple of Tensors out)\n * (Tensor input, name dim, bool keepdim, *, tuple of Tensors out)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "\n",
    "# Converting probabilities to class labels\n",
    "_, predicted_labels = torch.max(labels, 1)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "# Convert to numpy arrays for compatibility with sklearn\n",
    "true_labels_np = preds.numpy()\n",
    "predicted_labels_np = predicted_labels.numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "precision = precision_score(true_labels_np, predicted_labels_np)\n",
    "recall = recall_score(true_labels_np, predicted_labels_np)\n",
    "f1 = f1_score(true_labels_np, predicted_labels_np)\n",
    "accuracy = accuracy_score(true_labels_np, predicted_labels_np)\n",
    "\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
